{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305ac04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.stats import pearsonr, zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception:\n",
    "    pass\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def compute_pearson_r2(y_true, y_pred):\n",
    "    if len(y_true) <= 2:\n",
    "        return np.nan\n",
    "    if np.std(y_pred) < 1e-7 or np.std(y_true) < 1e-7:\n",
    "        return np.nan\n",
    "    r, _ = pearsonr(y_true, y_pred)\n",
    "    return r * r\n",
    "\n",
    "def create_mask(X):\n",
    "    return np.all(~np.isnan(X), axis=3, keepdims=True).astype(np.float32)\n",
    "\n",
    "def normalize_data(X_train, X_val, X_test):\n",
    "    band_mean = np.nanmean(X_train, axis=(0, 1, 2))\n",
    "    band_std = np.nanstd(X_train, axis=(0, 1, 2))\n",
    "    band_std[band_std < 1e-7] = 1.0\n",
    "\n",
    "    def norm(A):\n",
    "        return np.where(np.isnan(A), np.nan, (A - band_mean) / band_std)\n",
    "\n",
    "    return norm(X_train), norm(X_val), norm(X_test), band_mean, band_std\n",
    "\n",
    "def time_split(X, y, meta, cutoff_date=\"20240101\"):\n",
    "    cutoff = datetime.datetime.strptime(cutoff_date, \"%Y%m%d\")\n",
    "    before_idx = [i for i, m in enumerate(meta) if datetime.datetime.strptime(m[\"date\"], \"%Y%m%d\") < cutoff]\n",
    "    test_idx = [i for i, m in enumerate(meta) if datetime.datetime.strptime(m[\"date\"], \"%Y%m%d\") >= cutoff]\n",
    "    if len(before_idx) == 0 or len(test_idx) == 0:\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        meta_tr, meta_te = train_test_split(meta, test_size=0.2, random_state=42)\n",
    "        return X_tr, y_tr, meta_tr, X_te, y_te, meta_te\n",
    "    return (X[before_idx], y[before_idx], [meta[i] for i in before_idx],\n",
    "            X[test_idx], y[test_idx], [meta[i] for i in test_idx])\n",
    "\n",
    "def filter_by_zscore_and_ratio(X, y, meta, z_threshold=2.5, min_valid_ratio=0.5):\n",
    "    nan_ratios = np.mean(np.isnan(X), axis=(1, 2, 3))\n",
    "    valid_ratios = 1 - nan_ratios\n",
    "    z_scores = zscore(nan_ratios)\n",
    "    keep_mask = (z_scores <= z_threshold) & (valid_ratios >= min_valid_ratio)\n",
    "    idx = np.where(keep_mask)[0]\n",
    "    return X[idx], y[idx], [meta[i] for i in idx]\n",
    "\n",
    "_ONES_CACHE = {}\n",
    "\n",
    "def _get_ones(device, dtype, k):\n",
    "    key = (device, dtype, k)\n",
    "    if key not in _ONES_CACHE:\n",
    "        _ONES_CACHE[key] = torch.ones(1, 1, k, k, device=device, dtype=dtype)\n",
    "    return _ONES_CACHE[key]\n",
    "\n",
    "def pconv3x3_like(x, mask, conv3x3: nn.Conv2d):\n",
    "    x_masked = x * mask\n",
    "    y = conv3x3(x_masked)\n",
    "    k = conv3x3.kernel_size[0]\n",
    "    ones = _get_ones(x.device, x.dtype, k)\n",
    "    cnt = F.conv2d(mask, ones, bias=None, stride=conv3x3.stride, padding=conv3x3.padding, dilation=conv3x3.dilation)\n",
    "    scale = (k * k) / torch.clamp(cnt, min=1.0)\n",
    "    y = y * scale\n",
    "    new_mask = (cnt > 0).to(x.dtype)\n",
    "    y = y * new_mask\n",
    "    return y, new_mask\n",
    "\n",
    "def _kernel_area(k):\n",
    "    if isinstance(k, tuple):\n",
    "        return int(k[0]) * int(k[1])\n",
    "    return int(k) * int(k)\n",
    "\n",
    "def masked_avgpool2d(x, mask, k=2, s=2):\n",
    "    area = _kernel_area(k)\n",
    "    sum_x = F.avg_pool2d(x * mask, k, s) * area\n",
    "    cnt = F.avg_pool2d(mask, k, s) * area\n",
    "    out = sum_x / torch.clamp(cnt, min=1.0)\n",
    "    new_mask = (cnt > 0).to(x.dtype)\n",
    "    out = out * new_mask\n",
    "    return out, new_mask\n",
    "\n",
    "class EnhancedCNNModel(nn.Module):\n",
    "    def __init__(self, input_channels=41):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Dropout(0.4),\n",
    "        )\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = torch.nan_to_num(x, nan=0.0)\n",
    "\n",
    "        x, mask = pconv3x3_like(x, mask, self.conv_block1[0])\n",
    "        x = self.conv_block1[1](x)\n",
    "        x = self.conv_block1[2](x)\n",
    "        x, mask = pconv3x3_like(x, mask, self.conv_block1[3])\n",
    "        x = self.conv_block1[4](x)\n",
    "        x = self.conv_block1[5](x)\n",
    "        x, mask = masked_avgpool2d(x, mask, k=2, s=2)\n",
    "        x = self.conv_block1[7](x)\n",
    "\n",
    "        x, mask = pconv3x3_like(x, mask, self.conv_block2[0])\n",
    "        x = self.conv_block2[1](x)\n",
    "        x = self.conv_block2[2](x)\n",
    "        x, mask = pconv3x3_like(x, mask, self.conv_block2[3])\n",
    "        x = self.conv_block2[4](x)\n",
    "        x = self.conv_block2[5](x)\n",
    "        x, mask = masked_avgpool2d(x, mask, k=2, s=2)\n",
    "        x = self.conv_block2[7](x)\n",
    "\n",
    "        x, mask = pconv3x3_like(x, mask, self.conv_block3[0])\n",
    "        x = self.conv_block3[1](x)\n",
    "        x = self.conv_block3[2](x)\n",
    "        x, mask = pconv3x3_like(x, mask, self.conv_block3[3])\n",
    "        x = self.conv_block3[4](x)\n",
    "        x = self.conv_block3[5](x)\n",
    "        H, W = x.shape[-2:]\n",
    "        x, mask = masked_avgpool2d(x, mask, k=(H, W), s=(H, W))\n",
    "        x = self.conv_block3[7](x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_block(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    y_final_tp = y_final[:, 0]\n",
    "    X_filtered, y_filtered, meta_filtered = filter_by_zscore_and_ratio(X_final, y_final_tp, meta_final)\n",
    "    X_before, y_before, meta_before, X_test, y_test, meta_test = time_split(X_filtered, y_filtered, meta_filtered)\n",
    "    X_train, X_val, y_train, y_val, meta_train, meta_val = train_test_split(\n",
    "        X_before, y_before, meta_before, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    y_train_log = np.log(np.clip(y_train, 1e-6, np.inf))\n",
    "    y_val_log = np.log(np.clip(y_val, 1e-6, np.inf))\n",
    "    y_test_log = np.log(np.clip(y_test, 1e-6, np.inf))\n",
    "\n",
    "    X_train_norm, X_val_norm, X_test_norm, band_mean, band_std = normalize_data(X_train, X_val, X_test)\n",
    "\n",
    "    mask_train = create_mask(X_train)\n",
    "    mask_val = create_mask(X_val)\n",
    "    mask_test = create_mask(X_test)\n",
    "\n",
    "    def to_tensor_4d(X):\n",
    "        return torch.tensor(X, dtype=torch.float32).permute(0, 3, 1, 2).contiguous(memory_format=torch.channels_last)\n",
    "\n",
    "    def to_tensor_mask(M):\n",
    "        return torch.tensor(M, dtype=torch.float32).permute(0, 3, 1, 2).contiguous(memory_format=torch.channels_last)\n",
    "\n",
    "    X_train_t = to_tensor_4d(X_train_norm)\n",
    "    X_val_t = to_tensor_4d(X_val_norm)\n",
    "    X_test_t = to_tensor_4d(X_test_norm)\n",
    "    M_train_t = to_tensor_mask(mask_train)\n",
    "    M_val_t = to_tensor_mask(mask_val)\n",
    "    M_test_t = to_tensor_mask(mask_test)\n",
    "    y_train_t = torch.tensor(y_train_log, dtype=torch.float32)\n",
    "    y_val_t = torch.tensor(y_val_log, dtype=torch.float32)\n",
    "    y_test_t = torch.tensor(y_test_log, dtype=torch.float32)\n",
    "\n",
    "    batch_size = 128 if torch.cuda.is_available() else 32\n",
    "    num_workers = min(8, os.cpu_count() or 1)\n",
    "    persistent = num_workers > 0\n",
    "    prefetch = 4 if num_workers > 0 else None\n",
    "\n",
    "    def make_loader(dataset, shuffle):\n",
    "        kwargs = dict(batch_size=batch_size, shuffle=shuffle, pin_memory=True, num_workers=num_workers)\n",
    "        if persistent:\n",
    "            kwargs[\"persistent_workers\"] = True\n",
    "        if prefetch is not None:\n",
    "            kwargs[\"prefetch_factor\"] = prefetch\n",
    "        return DataLoader(dataset, **kwargs)\n",
    "\n",
    "    train_loader = make_loader(TensorDataset(X_train_t, M_train_t, y_train_t), True)\n",
    "    val_loader = make_loader(TensorDataset(X_val_t, M_val_t, y_val_t), False)\n",
    "    test_loader = make_loader(TensorDataset(X_test_t, M_test_t, y_test_t), False)\n",
    "\n",
    "    train_eval_loader = make_loader(TensorDataset(X_train_t, M_train_t, y_train_t), False)\n",
    "\n",
    "    base_model = EnhancedCNNModel(input_channels=X_train_t.shape[1]).to(device)\n",
    "    base_model = base_model.to(memory_format=torch.channels_last)\n",
    "\n",
    "    model = base_model\n",
    "    if device.type == \"cuda\" and torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(base_model).to(device)\n",
    "\n",
    "    criterion = nn.SmoothL1Loss(beta=0.5)\n",
    "\n",
    "    try:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4, fused=True)\n",
    "    except TypeError:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=torch.cuda.is_available())\n",
    "\n",
    "    BN_FREEZE_EPOCH = 5\n",
    "\n",
    "    def _freeze_bn(m):\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.eval()\n",
    "\n",
    "    def apply_to_model(m, fn):\n",
    "        if isinstance(m, nn.DataParallel):\n",
    "            m.module.apply(fn)\n",
    "        else:\n",
    "            m.apply(fn)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_state = copy.deepcopy(model.state_dict())\n",
    "    patience = 10\n",
    "    patience_ctr = 0\n",
    "\n",
    "    for epoch in range(1, 101):\n",
    "        if epoch == BN_FREEZE_EPOCH:\n",
    "            apply_to_model(model, _freeze_bn)\n",
    "\n",
    "        model.train()\n",
    "        tr_sum = 0.0\n",
    "        for Xb, Mb, yb in train_loader:\n",
    "            Xb = Xb.to(device, non_blocking=True)\n",
    "            Mb = Mb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.autocast(\"cuda\", enabled=torch.cuda.is_available()):\n",
    "                out = model(Xb, Mb)\n",
    "                loss = criterion(out, yb)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            tr_sum += loss.item() * Xb.size(0)\n",
    "\n",
    "        model.eval()\n",
    "        va_sum = 0.0\n",
    "        with torch.no_grad(), torch.autocast(\"cuda\", enabled=torch.cuda.is_available()):\n",
    "            for Xb, Mb, yb in val_loader:\n",
    "                Xb = Xb.to(device, non_blocking=True)\n",
    "                Mb = Mb.to(device, non_blocking=True)\n",
    "                yb = yb.to(device, non_blocking=True)\n",
    "                out = model(Xb, Mb)\n",
    "                va_sum += criterion(out, yb).item() * Xb.size(0)\n",
    "\n",
    "        val_loss = va_sum / len(val_loader.dataset)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss - 1e-6:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            patience_ctr = 0\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "            if patience_ctr >= patience:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    def predict_on_loader(loader):\n",
    "        model.eval()\n",
    "        pred_log, true_log = [], []\n",
    "        with torch.no_grad(), torch.autocast(\"cuda\", enabled=torch.cuda.is_available()):\n",
    "            for Xb, Mb, yb_log in loader:\n",
    "                Xb = Xb.to(device, non_blocking=True)\n",
    "                Mb = Mb.to(device, non_blocking=True)\n",
    "                yb_log = yb_log.to(device, non_blocking=True)\n",
    "                out_log = model(Xb, Mb).float().squeeze(-1)\n",
    "                pred_log.append(out_log.detach().cpu().numpy())\n",
    "                true_log.append(yb_log.detach().cpu().numpy())\n",
    "        y_pred_log = np.concatenate(pred_log)\n",
    "        y_true_log = np.concatenate(true_log)\n",
    "        y_pred = np.exp(y_pred_log) - 1e-6\n",
    "        y_true = np.exp(y_true_log) - 1e-6\n",
    "        return y_true, y_pred\n",
    "\n",
    "    y_train_true, y_train_pred = predict_on_loader(train_eval_loader)\n",
    "    y_val_true, y_val_pred = predict_on_loader(val_loader)\n",
    "    y_test_true, y_test_pred = predict_on_loader(test_loader)\n",
    "\n",
    "    def metrics(y_true, y_pred):\n",
    "        return {\n",
    "            \"PearsonR2\": compute_pearson_r2(y_true, y_pred),\n",
    "            \"MAE\": float(np.mean(np.abs(y_true - y_pred))),\n",
    "            \"RMSE\": float(np.sqrt(np.mean((y_true - y_pred) ** 2))),\n",
    "            \"SD_pred\": float(np.std(y_pred)),\n",
    "            \"N\": int(len(y_true)),\n",
    "        }\n",
    "\n",
    "    m_train = metrics(y_train_true, y_train_pred)\n",
    "    m_val = metrics(y_val_true, y_val_pred)\n",
    "    m_test = metrics(y_test_true, y_test_pred)\n",
    "\n",
    "    def _safe_site_id(m):\n",
    "        if isinstance(m, dict):\n",
    "            return m.get(\"site_id\", m.get(\"index\", m.get(\"id\", None)))\n",
    "        for k in (\"site_id\", \"index\", \"id\"):\n",
    "            if hasattr(m, k):\n",
    "                return getattr(m, k)\n",
    "        return None\n",
    "\n",
    "    train_dates = np.array([m[\"date\"] for m in meta_train])\n",
    "    val_dates = np.array([m[\"date\"] for m in meta_val])\n",
    "    test_dates = np.array([m[\"date\"] for m in meta_test])\n",
    "\n",
    "    train_site_ids = np.array([_safe_site_id(m) for m in meta_train])\n",
    "    val_site_ids = np.array([_safe_site_id(m) for m in meta_val])\n",
    "    test_site_ids = np.array([_safe_site_id(m) for m in meta_test])\n",
    "\n",
    "    np.savez(\n",
    "        \"tp_predictions_train_val_test.npz\",\n",
    "        y_train_true=y_train_true, y_train_pred=y_train_pred,\n",
    "        y_val_true=y_val_true, y_val_pred=y_val_pred,\n",
    "        y_test_true=y_test_true, y_test_pred=y_test_pred,\n",
    "        train_dates=train_dates, train_site_ids=train_site_ids,\n",
    "        val_dates=val_dates, val_site_ids=val_site_ids,\n",
    "        test_dates=test_dates, test_site_ids=test_site_ids,\n",
    "        meta_train=np.array(meta_train, dtype=object),\n",
    "        meta_val=np.array(meta_val, dtype=object),\n",
    "        meta_test=np.array(meta_test, dtype=object),\n",
    "        metrics_train=m_train, metrics_val=m_val, metrics_test=m_test,\n",
    "    )\n",
    "\n",
    "    state_to_save = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
    "    ckpt = {\n",
    "        \"state_dict\": state_to_save,\n",
    "        \"band_mean\": band_mean.astype(np.float32).tolist(),\n",
    "        \"band_std\": band_std.astype(np.float32).tolist(),\n",
    "        \"input_channels\": int(X_train_t.shape[1]),\n",
    "        \"arch\": \"EnhancedCNNModel(mask-aware v1)\",\n",
    "    }\n",
    "    torch.save(ckpt, \"tp_maskaware_checkpoint.pt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
